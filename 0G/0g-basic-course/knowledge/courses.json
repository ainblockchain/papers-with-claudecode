[
  {
    "id": "understanding_0g",
    "title": "Module 1: Understanding 0G",
    "description": "Get a clear picture of what 0G is, why it exists, and how its four core services work together to power decentralized AI applications.",
    "concepts": ["what_is_0g", "four_services_overview", "why_decentralized_ai", "0g_ecosystem"],
    "lessons": [
      {
        "concept_id": "what_is_0g",
        "title": "What is 0G? The Decentralized AI Operating System",
        "prerequisites": [],
        "key_ideas": [
          "0G is the world's first decentralized AI operating system (deAIOS)",
          "It provides infrastructure — storage, compute, data availability — so developers don't build from scratch",
          "Purpose-built for AI workloads: high throughput, low cost, trustless guarantees"
        ],
        "code_ref": "",
        "paper_ref": "0G Labs, 2024 — 0G Developer Documentation (docs.0g.ai)",
        "exercise": "What best describes 0G?\n1) A cryptocurrency token for buying AI services\n2) A decentralized AI operating system providing infrastructure for AI applications\n3) A cloud provider competing with AWS\nType the number.",
        "explanation": "0G Labs describes 0G as a 'decentralized AI operating system' — and the analogy is intentional. Just as an operating system (Windows, Linux, macOS) provides a foundation that applications build on top of, 0G provides foundational AI infrastructure that any developer or application can use without building their own data centers.\n\nThink about what it takes to build an AI application today:\n- You need a place to store training datasets and model weights (terabytes of data)\n- You need GPUs to train and run inference\n- You need a way to verify that computations happened correctly\n- You need a blockchain for provenance and payments\n\nAll of this typically comes from centralized cloud providers: AWS for storage, OpenAI or Bedrock for inference, Ethereum for on-chain logic. Each provider charges a markup for their infrastructure.\n\n0G replaces this stack with a single, unified, decentralized platform:\n- **Cheaper**: 95% less than AWS for storage, 90% less than OpenAI for inference\n- **Permissionless**: No API keys to request, no accounts to approve\n- **Trustless**: Cryptographic proofs replace trust in any single company\n- **Composable**: The four services work together natively\n\nFor AI applications specifically, 0G removes the infrastructure bottleneck. Developers can focus on building instead of managing cloud services.",
        "x402_price": "",
        "x402_gateway": ""
      },
      {
        "concept_id": "four_services_overview",
        "title": "The Four Services: Chain, Storage, Compute, DA",
        "prerequisites": ["what_is_0g"],
        "key_ideas": [
          "0G Chain: EVM-compatible L1 blockchain, 11,000 TPS, smart contracts",
          "0G Storage: Decentralized file storage, 95% cheaper than AWS S3",
          "0G Compute: Decentralized GPU marketplace, 90% cheaper than OpenAI",
          "0G DA: Data availability layer, 50 Gbps throughput for rollups"
        ],
        "code_ref": "",
        "paper_ref": "0G Labs, 2024 — 0G Developer Documentation (docs.0g.ai)",
        "exercise": "You need to store a large AI model file (10GB) for your application. Which 0G service handles this?\n1) 0G Chain\n2) 0G Storage\n3) 0G Compute\nType the number.",
        "explanation": "0G has four distinct services, each solving a specific infrastructure problem for AI applications:\n\n**0G Chain — The Programmable Layer**\nThis is an EVM-compatible Layer 1 blockchain. If you know Ethereum, you already know 0G Chain — the same Solidity contracts, MetaMask wallets, and ethers.js code work without modification. It processes 11,000 transactions per second (vs Ethereum's ~15 TPS) with sub-second finality. This is where your smart contracts live, where payments settle, and where data provenance is recorded.\n\n**0G Storage — The File System**\nDecentralized storage for any file type: datasets, model weights, documents, images. Files are content-addressed (identified by their Merkle root hash) and replicated across hundreds of nodes. No single company holds your data. Price: ~5% of AWS S3. Retrieval speed: 200 MBPS. This is where your AI's data lives.\n\n**0G Compute — The Execution Engine**\nA marketplace of GPU providers running AI inference and fine-tuning. The API is OpenAI-compatible — existing apps can switch with two lines of code. Providers compete on price, driving costs 90% below centralized alternatives. This is where your AI thinking happens.\n\n**0G DA — The Data Availability Backbone**\nHigh-throughput data availability for rollups (Layer 2 blockchains). At 50 Gbps, it's orders of magnitude above Ethereum's DA capacity. If you're building a rollup or L2, this is where your transaction data goes for verification without full on-chain storage.\n\nFor most developers getting started, you'll interact with Chain, Storage, and Compute. DA becomes relevant when you're building at L2 scale.",
        "x402_price": "",
        "x402_gateway": ""
      },
      {
        "concept_id": "why_decentralized_ai",
        "title": "Why Decentralized AI Infrastructure Matters",
        "prerequisites": ["four_services_overview"],
        "key_ideas": [
          "Centralized AI creates single points of failure and censorship",
          "Decentralization enables permissionless access and verifiable computation",
          "Open competition between providers drives costs down dramatically"
        ],
        "code_ref": "",
        "paper_ref": "0G Labs, 2024 — 0G Developer Documentation (docs.0g.ai)",
        "exercise": "What is the main economic advantage of decentralized AI infrastructure like 0G?\n1) It uses newer hardware than cloud providers\n2) Open competition between providers eliminates centralized markup\n3) Decentralized systems always have lower latency\nType the number.",
        "explanation": "Why not just use AWS or OpenAI? This is a fair question, and understanding the answer helps you use 0G more effectively.\n\n**The centralization problem:**\n\nWhen you use AWS S3, you're trusting Amazon to:\n- Keep your data available\n- Not change pricing unexpectedly\n- Not delete or censor your data\n- Not be hacked or go down\n\nWhen you use OpenAI's API, you're trusting OpenAI to:\n- Keep running their service\n- Not rate-limit or ban your application\n- Provide accurate AI responses\n- Not change pricing or terms\n\nFor many applications, this trust is acceptable. But for AI applications that need to operate at scale, across geographies, or in adversarial environments, centralization is a liability.\n\n**The economics of decentralization:**\n\nCentralized providers charge market rates because there's limited competition at scale. AWS S3 pricing includes Amazon's infrastructure costs plus a significant markup for their support, reliability, and profit margin.\n\n0G flips this: hundreds of storage miners and GPU operators compete directly for your work. The Flow smart contract and Compute Ledger act as trustless marketplace coordinators. Competition drives prices to hardware costs — that's why 0G achieves 95% cost reduction for storage and 90% for compute.\n\n**The verifiability advantage:**\n\n0G uses cryptographic proofs to verify that:\n- Your file is actually stored (Proof of Random Access)\n- The AI inference was actually performed correctly (ZK proofs)\n- Data is available for rollup verification (KZG commitments)\n\nYou don't have to trust anyone — the math proves it.",
        "x402_price": "",
        "x402_gateway": ""
      },
      {
        "concept_id": "0g_ecosystem",
        "title": "The 0G Ecosystem: Networks, Tokens, and Resources",
        "prerequisites": ["four_services_overview"],
        "key_ideas": [
          "Two networks: Testnet (Galileo, chainId 16602) and Mainnet (Aristotle, chainId 16661)",
          "Free testnet tokens at https://faucet.0g.ai for development",
          "Explorers at chainscan-galileo.0g.ai (testnet) and chainscan.0g.ai (mainnet)"
        ],
        "code_ref": "",
        "paper_ref": "0G Labs, 2024 — 0G Developer Documentation (docs.0g.ai)",
        "exercise": "Where can you get free 0G tokens to test your application?\n1) You must purchase them on a crypto exchange\n2) https://faucet.0g.ai — provides 0.1 0G per day for free\n3) They are automatically airdropped to new wallets\nType the number.",
        "explanation": "Before building on 0G, it helps to understand the ecosystem structure.\n\n**Two Networks:**\n\n| Network | Name | Chain ID | RPC |\n|---------|------|----------|-----|\n| Testnet | Galileo | 16602 | https://evmrpc-testnet.0g.ai |\n| Mainnet | Aristotle | 16661 | https://evmrpc.0g.ai |\n\nAlways develop and test on the Testnet first. Testnet tokens are free and have no real value — perfect for experimenting. Mainnet tokens have real value and are used for production applications.\n\n**Getting Testnet Tokens:**\n1. Go to https://faucet.0g.ai\n2. Connect your MetaMask wallet or paste your address\n3. Receive 0.1 0G per day (free)\n\n0G tokens are used for gas fees on 0G Chain. For storage and compute, you'll fund those services separately.\n\n**Key Resources:**\n- **Documentation**: https://docs.0g.ai\n- **Builder Hub**: https://build.0g.ai\n- **Chain Explorer (Testnet)**: https://chainscan-galileo.0g.ai\n- **Chain Explorer (Mainnet)**: https://chainscan.0g.ai\n- **Storage Explorer**: https://storagescan.0g.ai\n- **GitHub**: https://github.com/0gfoundation\n\n**The 0G Token (0G):**\nThe native token is used for gas fees on 0G Chain. For Storage, you pay in 0G tokens to miners via the Flow contract. For Compute, you deposit 0G tokens into an escrow that pays GPU providers. Everything is denominated in the same token, simplifying multi-service applications.",
        "x402_price": "",
        "x402_gateway": ""
      }
    ]
  },
  {
    "id": "getting_started",
    "title": "Module 2: Getting Started with 0G",
    "description": "Set up your wallet, get testnet tokens, and complete your first hands-on interactions with 0G Storage and 0G Compute.",
    "concepts": ["wallet_and_network_setup", "first_storage_upload", "first_ai_inference", "reading_chain_data"],
    "lessons": [
      {
        "concept_id": "wallet_and_network_setup",
        "title": "Setting Up Your Wallet for 0G",
        "prerequisites": ["0g_ecosystem"],
        "key_ideas": [
          "Use any EVM wallet (MetaMask recommended for beginners)",
          "Add 0G Testnet: Chain ID 16602, RPC https://evmrpc-testnet.0g.ai",
          "Store private key in .env file — never commit to git"
        ],
        "code_ref": "",
        "paper_ref": "0G Labs, 2024 — 0G Developer Documentation (docs.0g.ai)",
        "exercise": "What is the correct Chain ID to add 0G Galileo Testnet to MetaMask?\n1) 1 (Ethereum Mainnet)\n2) 16602\n3) 16661\nType the number.",
        "explanation": "Setting up for 0G development takes about 5 minutes.\n\n**Step 1: Get MetaMask (or any EVM wallet)**\nDownload MetaMask from metamask.io. Create a new account or use an existing one. Copy your wallet address (the 0x... string).\n\n**Step 2: Add 0G Testnet to MetaMask**\nIn MetaMask: Settings → Networks → Add Network → Add manually:\n```\nNetwork Name: 0G Galileo Testnet\nRPC URL:      https://evmrpc-testnet.0g.ai\nChain ID:     16602\nToken Symbol: 0G\nExplorer:     https://chainscan-galileo.0g.ai\n```\n\n**Step 3: Get testnet tokens**\n1. Go to https://faucet.0g.ai\n2. Paste your wallet address\n3. Click 'Request Tokens' — you'll receive 0.1 0G\n\n**Step 4: Set up your development environment**\n```bash\nmkdir my-0g-app && cd my-0g-app\nnpm init -y\nnpm install @0glabs/0g-ts-sdk ethers dotenv\n```\n\nCreate a `.env` file:\n```\nPRIVATE_KEY=your_private_key_here\n```\n\nCreate a `.gitignore` file:\n```\n.env\nnode_modules/\n```\n\n**CRITICAL**: Never share your private key or commit it to version control. The private key controls your wallet. Anyone with it can spend your funds. For testnet development, create a dedicated wallet with no real funds.\n\nVerify your setup:\n```typescript\nimport { ethers } from 'ethers';\nimport * as dotenv from 'dotenv';\ndotenv.config();\n\nconst provider = new ethers.JsonRpcProvider('https://evmrpc-testnet.0g.ai');\nconst signer = new ethers.Wallet(process.env.PRIVATE_KEY!, provider);\n\nconsole.log('Address:', signer.address);\nconsole.log('Balance:', await provider.getBalance(signer.address));\n```",
        "x402_price": "",
        "x402_gateway": ""
      },
      {
        "concept_id": "first_storage_upload",
        "title": "Your First File Upload to 0G Storage",
        "prerequisites": ["wallet_and_network_setup"],
        "key_ideas": [
          "ZgFile wraps your file and computes its Merkle root hash",
          "The rootHash is your file's permanent content-addressed ID — save it",
          "indexer.upload() handles payment and node selection automatically"
        ],
        "code_ref": "",
        "paper_ref": "0G Labs, 2024 — 0G Developer Documentation (docs.0g.ai)",
        "exercise": "After uploading a file to 0G Storage, what do you need to save to retrieve it later?\n1) The filename\n2) The rootHash — the Merkle tree root that content-addresses your file\n3) The transaction hash\nType the number.",
        "explanation": "Uploading a file to 0G Storage involves three steps: wrap the file, compute its identity (rootHash), and upload.\n\n```typescript\nimport { ZgFile, Indexer } from '@0glabs/0g-ts-sdk';\nimport { ethers } from 'ethers';\nimport * as dotenv from 'dotenv';\nimport * as fs from 'fs';\ndotenv.config();\n\nconst RPC_URL = 'https://evmrpc-testnet.0g.ai';\nconst INDEXER_URL = 'https://indexer-storage-testnet-turbo.0g.ai';\n\nasync function main() {\n  // Connect wallet\n  const provider = new ethers.JsonRpcProvider(RPC_URL);\n  const signer = new ethers.Wallet(process.env.PRIVATE_KEY!, provider);\n  const indexer = new Indexer(INDEXER_URL);\n\n  // Create a test file\n  fs.writeFileSync('hello.txt', 'Hello, 0G Storage!');\n\n  // Wrap the file\n  const file = await ZgFile.fromFilePath('./hello.txt');\n\n  // Compute Merkle tree (this determines the rootHash)\n  const [tree, treeErr] = await file.merkleTree();\n  if (treeErr) throw treeErr;\n\n  const rootHash = tree!.rootHash();\n  console.log('File identity (rootHash):', rootHash);\n  // ↑ SAVE THIS. It's how you retrieve the file.\n\n  // Upload to 0G Storage (handles payment automatically)\n  const [tx, uploadErr] = await indexer.upload(file, RPC_URL, signer);\n  if (uploadErr) throw uploadErr;\n\n  console.log('Upload complete! Transaction:', tx);\n  await file.close();\n\n  // Now download it back\n  const downloadErr = await indexer.download(rootHash, './hello-downloaded.txt', true);\n  if (downloadErr) throw downloadErr;\n  console.log('Downloaded:', fs.readFileSync('./hello-downloaded.txt', 'utf8'));\n}\n\nmain().catch(console.error);\n```\n\n**Understanding the rootHash:**\nThe rootHash is computed from your file's contents using a Merkle tree — a cryptographic data structure. Change even one byte, and the rootHash changes completely. This means:\n- You can verify a download is correct by checking the rootHash\n- Two identical files have the same rootHash (automatic deduplication)\n- There's no filename-based lookup — the rootHash IS your file's identity\n\n**What the upload does:**\n1. Splits your file into sectors\n2. Pays storage miners via the Flow contract\n3. Distributes data across storage nodes\n4. Returns a transaction hash confirming payment\n\nYou don't need to track individual storage nodes — the Indexer handles discovery and routing automatically.",
        "x402_price": "",
        "x402_gateway": ""
      },
      {
        "concept_id": "first_ai_inference",
        "title": "Your First AI Inference on 0G Compute",
        "prerequisites": ["wallet_and_network_setup"],
        "key_ideas": [
          "0G Compute is OpenAI API compatible — same SDK, 2-line change",
          "Must fund account and acknowledge provider before first request",
          "Available models include Llama-3, Qwen2.5, Mistral and more"
        ],
        "code_ref": "",
        "paper_ref": "0G Labs, 2024 — 0G Developer Documentation (docs.0g.ai)",
        "exercise": "How many lines of code need to change when migrating from OpenAI API to 0G Compute?\n1) Requires a complete rewrite of API calls\n2) Just 2 lines: change baseURL and apiKey\n3) At least 10 lines per API call\nType the number.",
        "explanation": "0G Compute uses the same API format as OpenAI, so migration is intentionally simple.\n\n**Setup (one-time):**\n```bash\n# Install the 0G Compute CLI\nnpm install -g @0glabs/0g-serving-broker\n\n# Login with your wallet\n0g-compute-cli login\n\n# Deposit funds\n0g-compute-cli deposit --amount 1\n\n# See available AI providers\n0g-compute-cli inference list-providers\n\n# Fund a specific provider (copy address from list above)\n0g-compute-cli transfer-fund --provider <PROVIDER_ADDRESS> --amount 0.5\n\n# Acknowledge the provider (required before first request)\n0g-compute-cli inference acknowledge-provider --provider <PROVIDER_ADDRESS>\n\n# Get your API key for this provider\n0g-compute-cli inference get-secret --provider <PROVIDER_ADDRESS>\n# → Copy the output: app-sk-xxxx... → set as ZG_API_KEY in .env\n```\n\n**Add to your .env:**\n```\nZG_API_KEY=app-sk-your-secret-here\nZG_PROVIDER_URL=https://provider-url-from-list\n```\n\n**Use it (2-line change from OpenAI):**\n```typescript\nimport OpenAI from 'openai';\nimport * as dotenv from 'dotenv';\ndotenv.config();\n\nconst client = new OpenAI({\n  apiKey: process.env.ZG_API_KEY,                        // was: OPENAI_API_KEY\n  baseURL: process.env.ZG_PROVIDER_URL + '/v1/proxy',   // was: default\n});\n\nconst response = await client.chat.completions.create({\n  model: 'meta-llama/Meta-Llama-3.1-8B-Instruct',\n  messages: [{ role: 'user', content: 'Explain 0G Storage in one sentence.' }]\n});\n\nconsole.log(response.choices[0].message.content);\n```\n\n**What happens behind the scenes:**\n1. Your request goes to the provider's endpoint\n2. The provider runs inference on their GPU hardware\n3. They return a `ZG-Res-Key` header for payment settlement\n4. Tokens are deducted from your escrow account\n\nFor TEE-verified providers, you call `broker.inference.processResponse()` to complete the payment proof. For standard providers, it's fully automatic.",
        "x402_price": "",
        "x402_gateway": ""
      },
      {
        "concept_id": "reading_chain_data",
        "title": "Reading Data from 0G Chain",
        "prerequisites": ["wallet_and_network_setup"],
        "key_ideas": [
          "0G Chain is EVM-compatible — use ethers.js or viem",
          "View transaction history on chainscan-galileo.0g.ai",
          "Smart contracts on 0G work identically to Ethereum"
        ],
        "code_ref": "",
        "paper_ref": "0G Labs, 2024 — 0G Developer Documentation (docs.0g.ai)",
        "exercise": "How do you interact with smart contracts on 0G Chain?\n1) Using a special 0G SDK — standard Ethereum tools don't work\n2) Using standard Ethereum tools (ethers.js, viem, web3.js) — 0G is EVM-compatible\n3) Only through the 0G CLI — no JavaScript SDK\nType the number.",
        "explanation": "Because 0G Chain is EVM-compatible, you interact with it exactly like Ethereum. All your existing Ethereum knowledge applies directly.\n\n**Reading basic chain data:**\n```typescript\nimport { ethers } from 'ethers';\n\nconst provider = new ethers.JsonRpcProvider('https://evmrpc-testnet.0g.ai');\n\n// Get current block number\nconst blockNumber = await provider.getBlockNumber();\nconsole.log('Current block:', blockNumber);\n\n// Get balance\nconst balance = await provider.getBalance('0xYOUR_ADDRESS');\nconsole.log('Balance:', ethers.formatEther(balance), '0G');\n\n// Get transaction details\nconst tx = await provider.getTransaction('0xTX_HASH');\nconsole.log('Transaction:', tx);\n```\n\n**Calling a smart contract:**\n```typescript\n// The Flow contract manages storage payments\nconst FLOW_ADDRESS = '0x22E03a6A89B950F1c82ec5e74F8eCa321a105296';\n\n// Minimal ABI for reading\nconst abi = ['function numStorageShards() view returns (uint256)'];\nconst flowContract = new ethers.Contract(FLOW_ADDRESS, abi, provider);\n\nconst shards = await flowContract.numStorageShards();\nconsole.log('Storage shards:', shards.toString());\n```\n\n**Using the Block Explorer:**\nGo to https://chainscan-galileo.0g.ai and you can:\n- Search any address, transaction, or block\n- See all transactions for a wallet address\n- Verify smart contract deployments\n- View token transfers and balances\n\nThe explorer works identically to Etherscan on Ethereum. If you've used Etherscan before, chainscan is immediately familiar.",
        "x402_price": "",
        "x402_gateway": ""
      }
    ]
  },
  {
    "id": "building_first_app",
    "title": "Module 3: Building Your First 0G App",
    "description": "Put it all together: design a simple application architecture using 0G services, connect storage with AI inference, and understand real-world patterns.",
    "concepts": ["app_architecture_basics", "storage_compute_integration", "on_chain_data_recording", "next_steps"],
    "lessons": [
      {
        "concept_id": "app_architecture_basics",
        "title": "Designing a Simple 0G Application",
        "prerequisites": ["first_storage_upload", "first_ai_inference"],
        "key_ideas": [
          "Use Storage for datasets and results — immutable, content-addressed",
          "Use Compute for AI processing — decentralized GPU inference",
          "Use Chain for provenance, payments, and coordination"
        ],
        "code_ref": "",
        "paper_ref": "0G Labs, 2024 — 0G Developer Documentation (docs.0g.ai)",
        "exercise": "In a 0G application that analyzes documents with AI, what service stores the original documents?\n1) 0G Compute — it processes and stores them\n2) 0G Storage — immutable file storage\n3) 0G Chain — as on-chain data\nType the number.",
        "explanation": "A well-designed 0G application assigns each service the job it's best at. Here's a practical framework:\n\n**Use 0G Storage when:**\n- You have files, datasets, or binary data\n- Data should be immutable and content-addressed\n- You need cryptographic proof of data integrity\n- Files are large (MB to TB scale)\n\n**Use 0G Compute when:**\n- You need AI inference (text generation, embeddings, image generation)\n- You want to run ML models without managing GPU hardware\n- You need OpenAI-compatible API with lower cost\n\n**Use 0G Chain when:**\n- You need trustless coordination between parties\n- You want to record provenance or audit trails on-chain\n- You're handling payments or access control\n- You need smart contract logic\n\n**Example: AI Document Analysis App**\n```\nArchitecture:\n1. User uploads document → 0G Storage (get rootHash)\n2. Store rootHash + metadata → 0G Chain smart contract\n3. Send document to AI → 0G Compute (get analysis)\n4. Store analysis result → 0G Storage (get resultHash)\n5. Record resultHash on-chain → links document to analysis permanently\n\nResult: Fully verifiable pipeline.\n         Anyone can verify which document was analyzed,\n         what AI model was used, and what the result was.\n```\n\nThe key design principle: **rootHash is the universal connector**. A rootHash from Storage can be stored in a smart contract on Chain, used as a reference for Compute jobs, or passed to other applications. This content-addressed identity ties the four services together.",
        "x402_price": "",
        "x402_gateway": ""
      },
      {
        "concept_id": "storage_compute_integration",
        "title": "Connecting Storage and Compute: A Working Example",
        "prerequisites": ["app_architecture_basics", "first_storage_upload", "first_ai_inference"],
        "key_ideas": [
          "Upload data to Storage → get rootHash",
          "Pass rootHash or data to Compute for AI processing",
          "Store AI results back to Storage for immutable audit trail"
        ],
        "code_ref": "",
        "paper_ref": "0G Labs, 2024 — 0G Developer Documentation (docs.0g.ai)",
        "exercise": "What is the correct sequence for a basic 0G Storage + Compute pipeline?\n1) Run Compute inference first, then store results in Storage\n2) Upload to Storage (get rootHash), run Compute inference, store results to Storage\n3) Register on Chain first, then upload to Storage, then run Compute\nType the number.",
        "explanation": "Here's a complete working example that combines 0G Storage and 0G Compute:\n\n```typescript\nimport { ZgFile, Indexer } from '@0glabs/0g-ts-sdk';\nimport OpenAI from 'openai';\nimport { ethers } from 'ethers';\nimport * as fs from 'fs';\nimport * as dotenv from 'dotenv';\ndotenv.config();\n\nconst RPC_URL = 'https://evmrpc-testnet.0g.ai';\nconst INDEXER_URL = 'https://indexer-storage-testnet-turbo.0g.ai';\n\nasync function analyzeDocument(docPath: string) {\n  // === STEP 1: Upload document to 0G Storage ===\n  const provider = new ethers.JsonRpcProvider(RPC_URL);\n  const signer = new ethers.Wallet(process.env.PRIVATE_KEY!, provider);\n  const indexer = new Indexer(INDEXER_URL);\n\n  const file = await ZgFile.fromFilePath(docPath);\n  const [tree] = await file.merkleTree();\n  const docRootHash = tree!.rootHash();\n  console.log('Document stored with rootHash:', docRootHash);\n\n  await indexer.upload(file, RPC_URL, signer);\n  await file.close();\n\n  // === STEP 2: Run AI analysis via 0G Compute ===\n  const client = new OpenAI({\n    apiKey: process.env.ZG_API_KEY,\n    baseURL: process.env.ZG_PROVIDER_URL + '/v1/proxy',\n  });\n\n  const docContent = fs.readFileSync(docPath, 'utf8');\n  const response = await client.chat.completions.create({\n    model: 'meta-llama/Meta-Llama-3.1-8B-Instruct',\n    messages: [\n      { role: 'system', content: 'Summarize documents concisely.' },\n      { role: 'user', content: `Summarize this document:\\n\\n${docContent}` }\n    ]\n  });\n\n  const summary = response.choices[0].message.content!;\n  console.log('AI Summary:', summary);\n\n  // === STEP 3: Store the AI result back to 0G Storage ===\n  fs.writeFileSync('result.json', JSON.stringify({\n    originalDoc: docRootHash,\n    summary,\n    timestamp: Date.now()\n  }));\n\n  const resultFile = await ZgFile.fromFilePath('./result.json');\n  const [resultTree] = await resultFile.merkleTree();\n  const resultRootHash = resultTree!.rootHash();\n\n  await indexer.upload(resultFile, RPC_URL, signer);\n  await resultFile.close();\n\n  console.log('\\nPipeline complete!');\n  console.log('Document rootHash:', docRootHash);\n  console.log('Result rootHash:', resultRootHash);\n  // Both hashes can be stored on-chain to link document → analysis permanently\n}\n\nanalyzeDocument('./my-document.txt').catch(console.error);\n```\n\nThis 3-step pattern — upload → process → store result — is the foundation of most 0G AI applications. The rootHash chain (docRootHash → resultRootHash) creates an immutable, verifiable audit trail of your entire AI pipeline.",
        "x402_price": "",
        "x402_gateway": ""
      },
      {
        "concept_id": "on_chain_data_recording",
        "title": "Recording Your Pipeline on 0G Chain",
        "prerequisites": ["app_architecture_basics", "reading_chain_data"],
        "key_ideas": [
          "Store rootHashes on-chain to create a verifiable provenance trail",
          "Smart contract events serve as tamper-proof audit logs",
          "Anyone can verify the full pipeline using on-chain + storage data"
        ],
        "code_ref": "",
        "paper_ref": "0G Labs, 2024 — 0G Developer Documentation (docs.0g.ai)",
        "exercise": "Why would you store rootHashes in a smart contract on 0G Chain?\n1) Because 0G Storage requires it to work\n2) To create a tamper-proof, publicly verifiable provenance trail\n3) Smart contracts on 0G automatically mirror all storage transactions\nType the number.",
        "explanation": "Storing rootHashes on-chain creates a verifiable link between your data (in 0G Storage) and the public blockchain record (on 0G Chain).\n\n**Simple provenance contract:**\n```solidity\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.19;\n\ncontract DataPipeline {\n    struct PipelineRecord {\n        bytes32 inputHash;    // rootHash of the input document\n        bytes32 outputHash;   // rootHash of the AI result\n        string modelUsed;     // which AI model was used\n        uint256 timestamp;    // when was this processed\n        address submitter;    // who ran this pipeline\n    }\n\n    PipelineRecord[] public records;\n\n    event PipelineRecorded(\n        bytes32 indexed inputHash,\n        bytes32 outputHash,\n        string modelUsed,\n        uint256 timestamp\n    );\n\n    function recordPipeline(\n        bytes32 inputHash,\n        bytes32 outputHash,\n        string calldata modelUsed\n    ) external {\n        records.push(PipelineRecord({\n            inputHash: inputHash,\n            outputHash: outputHash,\n            modelUsed: modelUsed,\n            timestamp: block.timestamp,\n            submitter: msg.sender\n        }));\n\n        emit PipelineRecorded(inputHash, outputHash, modelUsed, block.timestamp);\n    }\n\n    function getRecord(uint256 index) external view returns (PipelineRecord memory) {\n        return records[index];\n    }\n}\n```\n\n**Deploy to 0G Testnet:**\n```bash\n# Using Hardhat (set evmVersion: 'cancun' in config!)\nnpx hardhat run scripts/deploy.js --network 0g-testnet\n```\n\n**Call from TypeScript:**\n```typescript\nconst pipeline = new ethers.Contract(CONTRACT_ADDRESS, abi, signer);\nawait pipeline.recordPipeline(\n  docRootHash,    // from 0G Storage\n  resultRootHash, // from 0G Storage\n  'meta-llama/Meta-Llama-3.1-8B-Instruct'\n);\n```\n\nNow anyone can:\n1. Query your contract to find all pipeline records\n2. Use the inputHash to download the original document from 0G Storage\n3. Use the outputHash to download the AI result\n4. Verify nothing was tampered with (rootHash = cryptographic proof)\n\nThis is what 'verifiable AI' means in practice.",
        "x402_price": "",
        "x402_gateway": ""
      },
      {
        "concept_id": "next_steps",
        "title": "What's Next: From Basic to Advanced 0G Development",
        "prerequisites": ["storage_compute_integration", "on_chain_data_recording"],
        "key_ideas": [
          "Key-value storage (0G Storage KV) for mutable state",
          "Fine-tuning custom models on 0G Compute",
          "0G DA for rollup/L2 development at scale"
        ],
        "code_ref": "",
        "paper_ref": "0G Labs, 2024 — 0G Developer Documentation (docs.0g.ai)",
        "exercise": "You want to store frequently updated AI agent state (like a conversation history that changes per message). Which 0G Storage layer should you use?\n1) Log Layer (immutable) — create a new file for each state update\n2) KV Layer (mutable) — update key-value pairs as state changes\n3) 0G Chain — store the state directly in a smart contract\nType the number.",
        "explanation": "You've now built your first 0G application. Here's what to explore next:\n\n**0G Storage KV Layer (Mutable Storage):**\nBeyond immutable file storage, 0G offers a mutable key-value store — perfect for AI agent state, configuration, or any data that needs frequent updates.\n\n```typescript\nimport { Batcher, KvClient } from '@0glabs/0g-ts-sdk';\n\n// Write mutable state\nconst STREAM_ID = '0x' + '0'.repeat(63) + '1'; // your app's namespace\nbatcher.streamDataBuilder.set(STREAM_ID, key, value);\nawait batcher.exec();\n\n// Read the current state\nconst kvClient = new KvClient('http://kv-node-url:6789');\nconst value = await kvClient.getValue(STREAM_ID, key);\n```\n\n**0G Compute Fine-Tuning:**\nTrain a custom model on your own dataset using decentralized GPU resources:\n```bash\n0g-compute-cli fine-tuning create-task \\\n  --provider <PROVIDER> \\\n  --model Qwen2.5-0.5B-Instruct \\\n  --dataset-path ./my-dataset.jsonl\n```\n\n**0G DA for Rollups:**\nIf you're building a Layer 2 blockchain or rollup, integrate 0G DA to replace Ethereum's expensive EIP-4844 blobs with 0G's 50 Gbps throughput layer. Reduces rollup operating costs significantly.\n\n**Advanced Patterns:**\n- **INFT (ERC-7857)**: Tokenize AI models as NFTs with encrypted model weights\n- **AI Agent Storage Pattern**: Store model weights on Storage, run inference on Compute, record actions on Chain\n- **Goldsky Indexing**: GraphQL API and database streaming over 0G contract events\n\n**Continue learning:**\n- Official docs: https://docs.0g.ai\n- 0G Developer Course (this platform) — covers all five modules in depth\n- Builder Hub: https://build.0g.ai\n- GitHub examples: https://github.com/0gfoundation\n\nYou've completed the 0G Basic Course. You understand the four services, have uploaded files to Storage, run AI inference on Compute, and connected them with an on-chain provenance record. You're ready to build.",
        "x402_price": "",
        "x402_gateway": ""
      }
    ]
  }
]
